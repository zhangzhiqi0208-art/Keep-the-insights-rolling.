import httpx
import json
import os
import hashlib
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import asyncio
from dotenv import load_dotenv
from .prompt_service import prompt_service

# ç¡®ä¿åœ¨ä»»æ„å·¥ä½œç›®å½•ä¸‹éƒ½èƒ½æ­£ç¡®åŠ è½½ backend/.env
_BACKEND_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
load_dotenv(os.path.join(_BACKEND_DIR, ".env"))

class LLMService:
    """LLMæœåŠ¡ç±»ï¼Œé›†æˆDeepSeek API"""
    
    def __init__(self):
        # ç¯å¢ƒå˜é‡åœ¨æ­¤å¤„å†æ¬¡åŠ è½½å…œåº•ï¼ˆé¿å…çƒ­é‡è½½æ—¶ä¸¢å¤±ï¼‰
        if not os.getenv("DEEPSEEK_API_KEY"):
            load_dotenv(os.path.join(_BACKEND_DIR, ".env"))
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.base_url = "https://api.deepseek.com/v1"
        self.model = "deepseek-chat"
        # ä»prompté…ç½®ä¸­è¯»å–è®¾ç½®
        settings = prompt_service.get_settings()
        self.max_tokens = settings.get("max_tokens", 512)
        self.temperature = settings.get("temperature", 0.1)
        self.top_p = settings.get("top_p", 0.8)
        self.frequency_penalty = settings.get("frequency_penalty", 0.0)
        self.presence_penalty = settings.get("presence_penalty", 0.0)
        self.timeout = settings.get("timeout", 25.0)
        
        # æ™ºèƒ½ç¼“å­˜æœºåˆ¶ - æš‚æ—¶ç¦ç”¨ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡éƒ½ä½¿ç”¨LLM
        self.cache = {}  # å†…å­˜ç¼“å­˜
        self.cache_ttl = timedelta(minutes=1)  # ç¼“å­˜1åˆ†é’Ÿï¼ŒåŸºæœ¬ä¸ç¼“å­˜
        self.cache_file = os.path.join(_BACKEND_DIR, "llm_cache.json")
        # self._load_cache()  # æš‚æ—¶ä¸åŠ è½½ç¼“å­˜
        
        # HTTPè¿æ¥æ± ä¼˜åŒ–
        self.http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(self.timeout),
            limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
        )
        
        if not self.api_key:
            print("âš ï¸ æœªè®¾ç½®DEEPSEEK_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ")
    
    async def close(self):
        """å…³é—­HTTPè¿æ¥æ± """
        if hasattr(self, 'http_client'):
            await self.http_client.aclose()
    
    def _load_cache(self):
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                print(f"âœ… å·²åŠ è½½ {len(self.cache)} æ¡ç¼“å­˜è®°å½•")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            self.cache = {}
    
    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def _generate_cache_key(self, description: str, system_types: List[str], modules: List[str]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{description}|{','.join(system_types)}|{','.join(modules)}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def _get_cached_result(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜ç»“æœ"""
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            cached_time = datetime.fromisoformat(cached_data['timestamp'])
            if datetime.now() - cached_time < self.cache_ttl:
                print(f"ğŸš€ ä½¿ç”¨ç¼“å­˜ç»“æœï¼ŒèŠ‚çœAPIè°ƒç”¨")
                return cached_data['result']
            else:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                del self.cache[cache_key]
        return None
    
    def _cache_result(self, cache_key: str, result: Dict[str, Any]):
        """ç¼“å­˜ç»“æœ"""
        self.cache[cache_key] = {
            'result': result,
            'timestamp': datetime.now().isoformat()
        }
        # é™åˆ¶ç¼“å­˜å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
        if len(self.cache) > 1000:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]
        self._save_cache()
    
    async def analyze_feedback(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any],
        files: List = None
    ) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·åŸå£°"""
        try:
            # æš‚æ—¶ç¦ç”¨ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡éƒ½ä½¿ç”¨LLM
            # cache_key = self._generate_cache_key(description, system_types, modules)
            # cached_result = self._get_cached_result(cache_key)
            # if cached_result:
            #     return cached_result
            
            # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨API
            if self.api_key:
                try:
                    result = await self._deepseek_analysis(description, system_types, modules, template)
                    # æš‚æ—¶ä¸ç¼“å­˜ç»“æœï¼Œç¡®ä¿æ¯æ¬¡éƒ½ä½¿ç”¨LLM
                    # self._cache_result(cache_key, result)
                    return result
                except Exception as api_error:
                    print(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {api_error}")
                    print("é™çº§åˆ°æ¨¡æ‹Ÿåˆ†ææ¨¡å¼")
                    result = await self._mock_analysis(description, system_types, modules, template)
                    # æš‚æ—¶ä¸ç¼“å­˜æ¨¡æ‹Ÿåˆ†æç»“æœ
                    # self._cache_result(cache_key, result)
                    return result
            else:
                print("æœªé…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†ææ¨¡å¼")
                result = await self._mock_analysis(description, system_types, modules, template)
                # æš‚æ—¶ä¸ç¼“å­˜æ¨¡æ‹Ÿåˆ†æç»“æœ
                # self._cache_result(cache_key, result)
                return result
        except Exception as e:
            print(f"LLMåˆ†æå¤±è´¥: {e}")
            print("ä½¿ç”¨é™çº§åˆ†ææ¨¡å¼")
            return await self._fallback_analysis(description, system_types, modules, template)
    
    async def _deepseek_analysis(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨DeepSeek APIè¿›è¡Œæ™ºèƒ½åˆ†æ"""
        
        # æ„å»ºåˆ†ææç¤ºè¯
        prompt = self._build_analysis_prompt(description, system_types, modules, template)
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·ä½“éªŒåˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«è®¾è®¡ä½“éªŒé—®é¢˜æœ¬è´¨ï¼Œè¿›è¡Œä¸“ä¸šçš„åˆ†ç±»å’Œæ¸…æ´—çš„é˜è¿°ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "max_tokens": self.max_tokens,
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                    "frequency_penalty": self.frequency_penalty,
                    "presence_penalty": self.presence_penalty,
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # è§£æJSONå“åº”
                try:
                    analysis_result = json.loads(content)
                    return self._format_analysis_result(analysis_result)
                except json.JSONDecodeError:
                    # å¦‚æœè¿”å›çš„ä¸æ˜¯JSONï¼Œä½¿ç”¨æ–‡æœ¬è§£æ
                    return await self._parse_text_response(content, description, system_types, modules)
            else:
                print(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
                return await self._mock_analysis(description, system_types, modules, template)
    
    def _build_analysis_prompt(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç”¨æˆ·ä½“éªŒåˆ†æå¸ˆï¼Œå…·å¤‡ä¸°å¯Œçš„Bç«¯äº§å“è®¾è®¡ç»éªŒã€‚è¯·æ·±å…¥åˆ†æä»¥ä¸‹ç”¨æˆ·åŸå£°ï¼Œæä¾›ç²¾å‡†ã€ä¸ªæ€§åŒ–ã€é’ˆå¯¹æ€§çš„åˆ†æç»“æœã€‚

## ç”¨æˆ·åŸå£°ä¿¡æ¯
**åé¦ˆå†…å®¹ï¼š** {description}
**æ‰€å±åœ°åŒºï¼š** {', '.join(system_types)}
**å½’å±æ¨¡å—ï¼š** {', '.join(modules)}

## æ ¸å¿ƒåˆ†æåŸåˆ™
1. **ç²¾å‡†ç†è§£**ï¼šæ·±å…¥ç†è§£ç”¨æˆ·åŸå£°çš„çœŸå®æ„å›¾å’Œå…·ä½“åœºæ™¯
2. **ä¸ªæ€§åŒ–åˆ†æ**ï¼šæ ¹æ®å…·ä½“é—®é¢˜æä¾›é’ˆå¯¹æ€§çš„åˆ†æï¼Œé¿å…æ¨¡æ¿åŒ–
3. **é‡ç‚¹æç‚¼**ï¼šæŠ“ä½é—®é¢˜çš„æ ¸å¿ƒè¦ç‚¹ï¼Œé¿å…æ³›æ³›è€Œè°ˆ
4. **æ‰©å†™ä¼˜åŒ–**ï¼šåœ¨ä¿æŒåŸæ„çš„åŸºç¡€ä¸Šï¼Œæä¾›æ›´ä¸“ä¸šã€æ›´è¯¦ç»†çš„æè¿°

## åˆ†æè¦æ±‚

### 1. é—®é¢˜ç±»å‹åˆ†ç±»ï¼ˆç²¾å‡†åŒ¹é…ï¼Œé¿å…è¶‹åŒï¼‰
- **è®¾è®¡éœ€æ±‚ä¼˜åŒ–**ï¼šéœ€è¦æ”¹è¿›ç°æœ‰è®¾è®¡æˆ–æ–°å¢è®¾è®¡åŠŸèƒ½
- **äº¤äº’åŠŸèƒ½bug**ï¼šäº¤äº’é€»è¾‘é”™è¯¯ã€æ“ä½œæµç¨‹é—®é¢˜  
- **è§†è§‰è¿˜åŸåº¦bug**ï¼šè®¾è®¡ç¨¿ä¸å®ç°æ•ˆæœä¸ä¸€è‡´
- **å†å²é—ç•™**ï¼šé•¿æœŸå­˜åœ¨çš„è®¾è®¡é—®é¢˜

### 2. è§£å†³æ–¹å¼åˆ†ç±»
- **ä½“éªŒä¼˜åŒ–**ï¼šé€šè¿‡è®¾è®¡æ”¹è¿›æå‡ç”¨æˆ·ä½“éªŒ
- **éœ€æ±‚ä¼˜åŒ–**ï¼šéœ€è¦é‡æ–°å®šä¹‰æˆ–è°ƒæ•´äº§å“éœ€æ±‚

### 3. ä¼˜å…ˆçº§åˆ¤æ–­ï¼ˆåŸºäºå…·ä½“å½±å“ï¼‰
- **P0-ç´§æ€¥**ï¼šä¸¥é‡å½±å“æ ¸å¿ƒåŠŸèƒ½ä½¿ç”¨
- **P1-é«˜**ï¼šå½±å“ä¸»è¦ä¸šåŠ¡æµç¨‹
- **P2-ä¸­**ï¼šå½±å“éƒ¨åˆ†ç”¨æˆ·ä½“éªŒ
- **P3-ä½**ï¼šè½»å¾®ä½“éªŒé—®é¢˜

### 4. ä¸ªæ€§åŒ–å½±å“åˆ†æ
è¯·åŸºäºå…·ä½“é—®é¢˜åœºæ™¯ï¼Œåˆ†æï¼š
- å¯¹ç”¨æˆ·çš„å…·ä½“å½±å“ï¼ˆæ“ä½œæ•ˆç‡ã€ä½¿ç”¨ä½“éªŒç­‰ï¼‰
- å¯¹ä¸šåŠ¡çš„å…·ä½“å½±å“ï¼ˆæµç¨‹é˜»å¡ã€æ•ˆç‡æŸå¤±ç­‰ï¼‰
- å¯¹ç³»ç»Ÿçš„å…·ä½“å½±å“ï¼ˆæ€§èƒ½ã€ç¨³å®šæ€§ç­‰ï¼‰

### 5. é’ˆå¯¹æ€§è§£å†³æ–¹æ¡ˆ
åŸºäºå…·ä½“é—®é¢˜æä¾›ï¼š
- 2-3ä¸ªå…·ä½“å¯è¡Œçš„è§£å†³æ–¹æ¡ˆ
- æ¯ä¸ªæ–¹æ¡ˆåŒ…å«å®æ–½æ­¥éª¤å’Œé¢„æœŸæ•ˆæœ
- é¿å…é€šç”¨åŒ–æè¿°ï¼Œè¦é’ˆå¯¹å…·ä½“é—®é¢˜

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š

{{
    "predictedType": "é—®é¢˜ç±»å‹ï¼ˆè®¾è®¡éœ€æ±‚ä¼˜åŒ–/äº¤äº’åŠŸèƒ½bug/è§†è§‰è¿˜åŸåº¦bug/å†å²é—ç•™ï¼‰",
    "priority": "ä¼˜å…ˆçº§ï¼ˆP0-ç´§æ€¥/P1-é«˜/P2-ä¸­/P3-ä½ï¼‰",
    "confidence": 0.85,
    "impact": "è¯¦ç»†çš„å½±å“åˆ†æï¼ŒåŒ…æ‹¬å¯¹ç”¨æˆ·ã€ä¸šåŠ¡å’Œç³»ç»Ÿçš„å…·ä½“å½±å“",
    "recommendedSolutions": [
        "å…·ä½“çš„è§£å†³æ–¹æ¡ˆ1ï¼ŒåŒ…å«å®æ–½æ­¥éª¤",
        "å…·ä½“çš„è§£å†³æ–¹æ¡ˆ2ï¼ŒåŒ…å«å®æ–½æ­¥éª¤",
        "å¤‡é€‰è§£å†³æ–¹æ¡ˆ3ï¼ŒåŒ…å«å®æ–½æ­¥éª¤"
    ],
    "estimatedTime": "é¢„ä¼°ä¿®å¤æ—¶é—´ï¼ˆå¦‚ï¼š1-2ä¸ªå·¥ä½œæ—¥/3-5ä¸ªå·¥ä½œæ—¥/1-2å‘¨ï¼‰",
    "relatedModules": ["ç›¸å…³æ¨¡å—1", "ç›¸å…³æ¨¡å—2"],
    "processingMethod": {{
        "method": "è§£å†³æ–¹å¼ï¼ˆä½“éªŒä¼˜åŒ–/éœ€æ±‚ä¼˜åŒ–ï¼‰",
        "assignee": "è´Ÿè´£å›¢é˜Ÿï¼ˆå¼€å‘å›¢é˜Ÿ/äº§å“å›¢é˜Ÿ/è®¾è®¡å›¢é˜Ÿ/å®‰å…¨å›¢é˜Ÿï¼‰",
        "timeline": "å…·ä½“æ—¶é—´çº¿ï¼ˆå¦‚ï¼š1-2ä¸ªå·¥ä½œæ—¥ï¼‰",
        "escalation": "å‡çº§ç­–ç•¥ï¼ˆéœ€è¦ç«‹å³ä¸ŠæŠ¥/æŒ‰è®¡åˆ’å¤„ç†/ä¸‹ä¸ªç‰ˆæœ¬ï¼‰"
    }},
    "acceptanceCriteria": [
        "é—®é¢˜å¾—åˆ°æœ‰æ•ˆè§£å†³ï¼ŒåŠŸèƒ½æ­£å¸¸è¿è¡Œ",
        "ç”¨æˆ·ä½“éªŒæ˜æ˜¾æ”¹å–„ï¼Œæ“ä½œæµç•…",
        "æ— æ–°çš„ç›¸å…³é—®é¢˜äº§ç”Ÿï¼Œç³»ç»Ÿç¨³å®š",
        "ç¬¦åˆäº§å“è®¾è®¡è§„èŒƒå’Œç”¨æˆ·æœŸæœ›"
    ]
}}

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•markdownæ ‡è®°æˆ–å…¶ä»–æ ¼å¼ã€‚
"""
        return prompt
    
    def _format_analysis_result(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–åˆ†æç»“æœ"""
        return {
            "predictedType": analysis_data.get("predictedType", "ä½“éªŒé—®é¢˜"),
            "priority": analysis_data.get("priority", "ä¸­"),
            "confidence": analysis_data.get("confidence", 0.8),
            "impact": analysis_data.get("impact", "å½±å“ç”¨æˆ·ä½“éªŒ"),
            "recommendedSolutions": analysis_data.get("recommendedSolutions", ["ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ"]),
            "estimatedTime": analysis_data.get("estimatedTime", "3-5ä¸ªå·¥ä½œæ—¥"),
            "relatedModules": analysis_data.get("relatedModules", []),
            "processingMethod": analysis_data.get("processingMethod", {
                "method": "äº§å“ä¼˜åŒ–",
                "assignee": "äº§å“å›¢é˜Ÿ",
                "timeline": "3-5ä¸ªå·¥ä½œæ—¥",
                "escalation": "æ­£å¸¸å¤„ç†"
            }),
            "acceptanceCriteria": analysis_data.get("acceptanceCriteria", [
                "é—®é¢˜å¾—åˆ°æœ‰æ•ˆè§£å†³",
                "ç”¨æˆ·ä½“éªŒæ˜æ˜¾æ”¹å–„",
                "æ— æ–°çš„ç›¸å…³é—®é¢˜äº§ç”Ÿ"
            ]),
            "analysisConfidence": analysis_data.get("confidence", 0.8)
        }
    
    async def _parse_text_response(
        self, 
        content: str, 
        description: str, 
        system_types: List[str], 
        modules: List[str]
    ) -> Dict[str, Any]:
        """è§£ææ–‡æœ¬å“åº”"""
        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘ï¼šå›é€€åˆ°æ¨¡æ‹Ÿåˆ†æ
        return await self._mock_analysis(description, system_types, modules, {})
    
    async def _mock_analysis(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿåˆ†æï¼ˆå½“APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        
        # ä¼˜å…ˆå°è¯•LLMæ™ºèƒ½åŒ¹é…ï¼Œå¤±è´¥åˆ™ä½¿ç”¨å…³é”®è¯åŒ¹é…
        try:
            if self.api_key:
                print(f"ğŸ” å°è¯•LLMæ™ºèƒ½åŒ¹é…...")
                result = await self._llm_field_matching(description, system_types, modules, template)
                print(f"âœ… LLMæ™ºèƒ½åŒ¹é…æˆåŠŸ!")
                return result
            else:
                print(f"âš ï¸ æœªé…ç½®APIå¯†é’¥ï¼Œè·³è¿‡LLMåŒ¹é…")
        except Exception as e:
            print(f"âŒ LLMå­—æ®µåŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # åŸºäºå…³é”®è¯çš„æ™ºèƒ½åˆ†æï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        text = description.lower()
        
        # é—®é¢˜ç±»å‹é¢„æµ‹ - æ ¹æ®æ–°çš„åˆ†ç±»é€»è¾‘è¿›è¡Œåˆ†ç±»
        problem_type = "å†å²é—ç•™"  # é»˜è®¤å½’ç±»ä¸ºå†å²é—ç•™
        confidence = 0.7
        
        # ä¼˜å…ˆåˆ¤æ–­è§†è§‰è¿˜åŸåº¦bug
        visual_keywords = [
            "è¿˜åŸ", "å®ç°", "ä¸ä¸€è‡´", "åå·®", "æ•ˆæœ", "æ˜¾ç¤º", "æ¸²æŸ“", "é¢œè‰²", "å­—ä½“", "å°ºå¯¸", "å¯¹é½",
            "æ ·å¼", "æ–‡æ¡ˆ", "å±•ç¤º", "ä¸å…¨", "æˆªæ–­", "æº¢å‡º", "å¸ƒå±€", "æ’ç‰ˆ", "é—´è·", "è¾¹è·",
            "é€‰ä¸­", "çŠ¶æ€", "hover", "active", "focus", "å¤–è§‚", "ç•Œé¢", "UI", "è®¾è®¡ç¨¿",
            "åƒç´ ", "px", "å¤§å°", "ç²—ç»†", "å­—é‡", "è¡Œé«˜", "å­—é—´è·", "letter-spacing", "line-height",
            "é˜´å½±", "åœ†è§’", "è¾¹æ¡†", "èƒŒæ™¯", "é€æ˜åº¦", "æ¸å˜", "å›¾æ ‡", "å›¾ç‰‡", "å›¾ç‰‡æ˜¾ç¤º"
        ]
        # æ’é™¤è®¾è®¡éœ€æ±‚ä¼˜åŒ–çš„æƒ…å†µ
        design_optimization_keywords = ["è®¾è®¡è§„èŒƒ", "è§„èŒƒè°ƒæ•´", "çº¿ä¸Šç³»ç»Ÿ", "ç³»ç»Ÿå½±å“", "è®¾è®¡æ ‡å‡†", "å»ºè®®", "ä¼˜åŒ–", "ç»Ÿä¸€"]
        if any(keyword in text for keyword in visual_keywords) and not any(keyword in text for keyword in design_optimization_keywords):
            problem_type = "è§†è§‰è¿˜åŸåº¦bug"
            confidence = 0.8
        
        # å…¶æ¬¡åˆ¤æ–­äº¤äº’åŠŸèƒ½bug
        interaction_keywords = ["äº¤äº’", "æ“ä½œ", "ç‚¹å‡»", "æŒ‰é’®", "åŠŸèƒ½", "æ— æ³•", "ä¸èƒ½", "é”™è¯¯", "å¼‚å¸¸", "bug"]
        if any(keyword in text for keyword in interaction_keywords):
            problem_type = "äº¤äº’åŠŸèƒ½bug"
            confidence = 0.8
        
        # ç„¶ååˆ¤æ–­è®¾è®¡éœ€æ±‚ä¼˜åŒ–
        design_keywords = ["è®¾è®¡è§„èŒƒ", "è§„èŒƒè°ƒæ•´", "çº¿ä¸Šç³»ç»Ÿ", "ç³»ç»Ÿå½±å“", "è®¾è®¡æ ‡å‡†"]
        if any(keyword in text for keyword in design_keywords):
            problem_type = "è®¾è®¡éœ€æ±‚ä¼˜åŒ–"
            confidence = 0.8
        
        # å…¶ä»–æƒ…å†µé»˜è®¤ä¸ºå†å²é—ç•™
        
        # ä¼˜å…ˆçº§åˆ†æ - æ ¹æ®æ¨¡æ¿è¦æ±‚è¿›è¡Œåˆ†ç±»
        priority = "P2-ä¸­"
        p0_keywords = ["å´©æºƒ", "é—ªé€€", "æ— æ³•ç™»å½•", "æ•°æ®ä¸¢å¤±", "æ”¯ä»˜", "äº¤æ˜“", "æ ¸å¿ƒ", "ç´§æ€¥", "ä¸¥é‡", "å¿«ç‚¹", "å°½å¿«"]
        p1_keywords = ["åŠŸèƒ½", "å¼‚å¸¸", "é”™è¯¯", "bug", "å¤±æ•ˆ", "ä¸å·¥ä½œ", "æ•…éšœ"]
        p3_keywords = ["ç•Œé¢ä¼˜åŒ–", "ä½“éªŒæ”¹è¿›", "å»ºè®®", "å¸Œæœ›", "æœŸå¾…", "ä¼˜åŒ–", "ç¾åŒ–", "æ”¹è¿›"]
        
        if any(keyword in text for keyword in p0_keywords):
            priority = "P0-ç´§æ€¥"
            confidence = min(confidence + 0.1, 0.95)
        elif any(keyword in text for keyword in p1_keywords):
            priority = "P1-é«˜"
            confidence = min(confidence + 0.05, 0.9)
        elif any(keyword in text for keyword in p3_keywords):
            priority = "P3-ä½"
            confidence = max(confidence - 0.1, 0.6)
        
        # æ™ºèƒ½è§£å†³æ–¹æ¡ˆæ¨è - æ ¹æ®æ¨¡æ¿è¦æ±‚
        solutions = {
            "è®¾è®¡éœ€æ±‚ä¼˜åŒ–": [
                "ä¼˜åŒ–ç”¨æˆ·ç•Œé¢è®¾è®¡ï¼Œæå‡è§†è§‰æ•ˆæœå’Œç”¨æˆ·ä½“éªŒ",
                "æ”¹è¿›äº¤äº’è®¾è®¡ï¼Œç®€åŒ–æ“ä½œæµç¨‹",
                "ç»Ÿä¸€è®¾è®¡è§„èŒƒï¼Œä¿æŒç•Œé¢é£æ ¼ä¸€è‡´æ€§"
            ],
            "äº¤äº’åŠŸèƒ½bug": [
                "ä¿®å¤äº¤äº’é€»è¾‘é”™è¯¯ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸è¿è¡Œ",
                "å®Œå–„å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§",
                "å¢åŠ åŠŸèƒ½æµ‹è¯•è¦†ç›–ï¼Œé¢„é˜²ç±»ä¼¼é—®é¢˜å†æ¬¡å‘ç”Ÿ"
            ],
            "è§†è§‰è¿˜åŸåº¦bug": [
                "è°ƒæ•´è§†è§‰å®ç°ï¼Œç¡®ä¿ä¸è®¾è®¡ç¨¿ä¸€è‡´",
                "ä¼˜åŒ–æ¸²æŸ“æ•ˆæœï¼Œæå‡è§†è§‰è´¨é‡",
                "å»ºç«‹è®¾è®¡è¿˜åŸåº¦æ£€æŸ¥æœºåˆ¶"
            ],
            "å†å²é—ç•™": [
                "åˆ¶å®šå†å²é—®é¢˜å¤„ç†è®¡åˆ’ï¼Œé€æ­¥ä¼˜åŒ–",
                "é‡æ„ç›¸å…³æ¨¡å—ï¼Œæå‡ä»£ç è´¨é‡",
                "å»ºç«‹é—®é¢˜è·Ÿè¸ªæœºåˆ¶ï¼Œé¿å…é—®é¢˜ç§¯ç´¯"
            ]
        }
        
        # æ™ºèƒ½å¤„ç†æ–¹å¼ - æ ¹æ®æ¨¡æ¿è¦æ±‚
        processing_methods = {
            "P0-ç´§æ€¥": {
                "method": "ä½“éªŒä¼˜åŒ–" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "éœ€æ±‚ä¼˜åŒ–",
                "assignee": "è®¾è®¡å›¢é˜Ÿ" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "å¼€å‘å›¢é˜Ÿ",
                "timeline": "1-2ä¸ªå·¥ä½œæ—¥",
                "escalation": "éœ€è¦ç«‹å³ä¸ŠæŠ¥"
            },
            "P1-é«˜": {
                "method": "ä½“éªŒä¼˜åŒ–" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "éœ€æ±‚ä¼˜åŒ–",
                "assignee": "è®¾è®¡å›¢é˜Ÿ" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "å¼€å‘å›¢é˜Ÿ",
                "timeline": "3-5ä¸ªå·¥ä½œæ—¥",
                "escalation": "æŒ‰è®¡åˆ’å¤„ç†"
            },
            "P2-ä¸­": {
                "method": "ä½“éªŒä¼˜åŒ–" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "éœ€æ±‚ä¼˜åŒ–",
                "assignee": "è®¾è®¡å›¢é˜Ÿ" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "å¼€å‘å›¢é˜Ÿ",
                "timeline": "1-2å‘¨",
                "escalation": "æŒ‰è®¡åˆ’å¤„ç†"
            },
            "P3-ä½": {
                "method": "ä½“éªŒä¼˜åŒ–" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "éœ€æ±‚ä¼˜åŒ–",
                "assignee": "è®¾è®¡å›¢é˜Ÿ" if problem_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"] else "å¼€å‘å›¢é˜Ÿ",
                "timeline": "ä¸‹ä¸ªç‰ˆæœ¬",
                "escalation": "ä¸‹ä¸ªç‰ˆæœ¬"
            }
        }
        
        # æ™ºèƒ½å½±å“åˆ†æ - æ ¹æ®æ¨¡æ¿è¦æ±‚
        impact_analysis = {
            "è®¾è®¡éœ€æ±‚ä¼˜åŒ–": "å½±å“ç”¨æˆ·è§†è§‰ä½“éªŒå’Œç•Œé¢ç¾è§‚åº¦ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·æ»¡æ„åº¦ä¸‹é™",
            "äº¤äº’åŠŸèƒ½bug": "å½±å“ç”¨æˆ·æ“ä½œæµç¨‹ï¼Œå¯èƒ½å¯¼è‡´åŠŸèƒ½æ— æ³•æ­£å¸¸ä½¿ç”¨",
            "è§†è§‰è¿˜åŸåº¦bug": "å½±å“è®¾è®¡ä¸€è‡´æ€§ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·ä½“éªŒä¸é¢„æœŸä¸ç¬¦",
            "å†å²é—ç•™": "å½±å“ç³»ç»Ÿæ•´ä½“è´¨é‡ï¼Œå¯èƒ½å¯¼è‡´æŠ€æœ¯å€ºåŠ¡ç§¯ç´¯"
        }
        
        return {
            "predictedType": problem_type,
            "priority": priority,
            "confidence": confidence,
            "impact": impact_analysis.get(problem_type, "å½±å“ç”¨æˆ·ä½“éªŒï¼Œéœ€è¦åŠæ—¶å¤„ç†è§£å†³"),
            "recommendedSolutions": solutions.get(problem_type, ["æ ¹æ®é—®é¢˜å…·ä½“æƒ…å†µåˆ¶å®šé’ˆå¯¹æ€§è§£å†³æ–¹æ¡ˆ"]),
            "estimatedTime": processing_methods[priority]["timeline"],
            "relatedModules": modules,
            "processingMethod": processing_methods[priority],
            "acceptanceCriteria": [
                "é—®é¢˜å¾—åˆ°æœ‰æ•ˆè§£å†³ï¼ŒåŠŸèƒ½æ­£å¸¸è¿è¡Œ",
                "ç”¨æˆ·ä½“éªŒæ˜æ˜¾æ”¹å–„ï¼Œæ“ä½œæµç•…",
                "æ— æ–°çš„ç›¸å…³é—®é¢˜äº§ç”Ÿï¼Œç³»ç»Ÿç¨³å®š",
                "ç¬¦åˆäº§å“è®¾è®¡è§„èŒƒå’Œç”¨æˆ·æœŸæœ›"
            ],
            "analysisConfidence": confidence
        }
    
    async def _fallback_analysis(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é™çº§åˆ†æï¼ˆå½“æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        print("ä½¿ç”¨é™çº§åˆ†ææ¨¡å¼")
        
        return {
            "predictedType": "ä½“éªŒé—®é¢˜",
            "priority": "ä¸­",
            "confidence": 0.5,
            "impact": "éœ€è¦è¿›ä¸€æ­¥åˆ†æé—®é¢˜å½±å“",
            "recommendedSolutions": [
                "è¯·è¯¦ç»†æè¿°é—®é¢˜ç°è±¡å’ŒæœŸæœ›çš„è§£å†³æ–¹æ¡ˆ",
                "æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥ä¾¿è¿›è¡Œå‡†ç¡®åˆ†æ"
            ],
            "estimatedTime": "å¾…è¯„ä¼°",
            "relatedModules": modules,
            "processingMethod": {
                "method": "å¾…åˆ†æ",
                "assignee": "å¾…åˆ†é…",
                "timeline": "å¾…è¯„ä¼°",
                "escalation": "æ­£å¸¸å¤„ç†"
            },
            "acceptanceCriteria": [
                "é—®é¢˜å¾—åˆ°æœ‰æ•ˆè§£å†³",
                "ç”¨æˆ·éœ€æ±‚å¾—åˆ°æ»¡è¶³"
            ],
            "analysisConfidence": 0.5,
            "original_description": description,
            "system_types": system_types,
            "modules": modules
        }
    
    async def generate_title(
        self, 
        description: str, 
        problem_type: str, 
        system_types: List[str], 
        modules: List[str]
    ) -> str:
        """ç”Ÿæˆæ™ºèƒ½æ ‡é¢˜ï¼šä¼˜å…ˆç”¨ DeepSeekï¼Œå¤±è´¥åˆ™å›é€€åˆ°æœ¬åœ°è§„åˆ™"""
        # å¤„ç†å¤šé€‰åœ°åŒºå’Œç»ˆç«¯ï¼Œä½¿ç”¨+å·è¿æ¥
        region_names = "+".join(system_types) if len(system_types) > 1 else system_types[0]
        module_names = "+".join(modules) if len(modules) > 1 else modules[0]

        if self.api_key:
            try:
                # ä»prompté…ç½®ä¸­è·å–æ ‡é¢˜ç”Ÿæˆçš„prompt
                prompt_config = prompt_service.get_prompt(
                    "title_generation",
                    problem_type=problem_type,
                    module_names=module_names,
                    description=description
                )
                
                async with self.http_client as client:  # æ›´çŸ­çš„è¶…æ—¶æ—¶é—´
                    resp = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers={
                            "Authorization": f"Bearer {self.api_key}",
                            "Content-Type": "application/json"
                        },
                        json={
                            "model": self.model,
                            "messages": [
                                {"role": "system", "content": prompt_config["system"]},
                                {"role": "user", "content": prompt_config["user"]}
                            ],
                            "max_tokens": 32,
                            "temperature": self.temperature,
                            "top_p": self.top_p,
                            "frequency_penalty": self.frequency_penalty,
                            "presence_penalty": self.presence_penalty,
                            "stream": False
                        }
                    )
                if resp.status_code == 200:
                    content = resp.json()["choices"][0]["message"]["content"].strip()
                    # æ¸…ç†å†…å®¹å¹¶æ·»åŠ åœ°åŒºæ¨¡å—å‰ç¼€
                    clean_content = content.replace("\n", " ").replace("ã€", "").replace("ã€‘", "")[:40]
                    return self._add_region_module_prefix(clean_content, system_types, modules)
            except Exception:
                pass

        # é™çº§åˆ°ç»Ÿä¸€å·¥å…·å‡½æ•°
        from app.utils.title_utils import TitleUtils
        return TitleUtils.generate_title(description, system_types, modules, problem_type)
    
    def _add_region_module_prefix(self, title: str, system_types: List[str], modules: List[str]) -> str:
        """ä¸ºæ ‡é¢˜æ·»åŠ åœ°åŒºæ¨¡å—å‰ç¼€"""
        # å¤„ç†å¤šé€‰åœ°åŒºå’Œç»ˆç«¯
        if len(system_types) > 1:
            region = "+".join(system_types)
        else:
            region = system_types[0] if system_types else "æœªçŸ¥åœ°åŒº"
            
        # æ ¹æ®è¦æ±‚ï¼Œç»ˆç«¯åªæ˜¾ç¤ºç¬¬ä¸€ä¸ª
        module = modules[0] if modules else "æœªçŸ¥æ¨¡å—"
        
        # æ„å»ºå‰ç¼€æ ¼å¼ï¼šã€åœ°åŒºï¼šæ¨¡å—ã€‘
        prefix = f"ã€{region}ï¼š{module}ã€‘"
        
        # ç»„åˆå‰ç¼€å’ŒåŸæ ‡é¢˜
        return f"{prefix}{title}"
    
    def _optimize_title_content(self, content: str) -> str:
        """ä¼˜åŒ–æ ‡é¢˜å†…å®¹ï¼Œç¡®ä¿è¯­å¥é€šé¡º"""
        import re
        
        if not content:
            return content
        
        # æ™ºèƒ½ä¼˜åŒ–å¸¸è§è¡¨è¾¾ï¼Œç¡®ä¿è¯­å¥é€šé¡ºï¼ˆå…ˆåº”ç”¨ä¼˜åŒ–è§„åˆ™ï¼Œå†ç§»é™¤å†—ä½™è¯æ±‡ï¼‰
        optimizations = {
            # å°ºå¯¸é—®é¢˜ä¼˜åŒ–
            r'æŒ‰é’®çš„å°ºå¯¸ä¸å¯¹,å¤ªå°äº†,é«˜åº¦åº”è¯¥æ˜¯40px': 'æŒ‰é’®å°ºå¯¸è¿‡å°ï¼Œé«˜åº¦ä¸å¤Ÿ',
            r'å°ºå¯¸ä¸å¯¹,å¤ªå°äº†,é«˜åº¦åº”è¯¥æ˜¯40px': 'å°ºå¯¸è¿‡å°ï¼Œé«˜åº¦ä¸å¤Ÿ',
            r'æŒ‰é’®çš„å°ºå¯¸ä¸å¯¹,å¤ªå°äº†,é«˜åº¦': 'æŒ‰é’®å°ºå¯¸è¿‡å°ï¼Œé«˜åº¦ä¸å¤Ÿ',
            r'å°ºå¯¸ä¸å¯¹,å¤ªå°äº†,é«˜åº¦': 'å°ºå¯¸è¿‡å°ï¼Œé«˜åº¦ä¸å¤Ÿ',
            r'æŒ‰é’®çš„é«˜åº¦åº”è¯¥æ˜¯40px': 'æŒ‰é’®é«˜åº¦ä¸ç¬¦åˆè§„èŒƒ',
            r'é«˜åº¦åº”è¯¥æ˜¯40px': 'é«˜åº¦ä¸ç¬¦åˆè§„èŒƒ',
            r'æŒ‰é’®çš„é«˜åº¦': 'æŒ‰é’®é«˜åº¦å¼‚å¸¸',
            r'å°ºå¯¸ä¸å¯¹,å¤ªå°äº†': 'å°ºå¯¸è¿‡å°',
            r'å¤ªå°äº†,é«˜åº¦': 'é«˜åº¦è¿‡å°',
            r'æŒ‰é’®çš„å°ºå¯¸ä¸å¯¹': 'æŒ‰é’®å°ºå¯¸ä¸å¯¹',
            r'æŒ‰é’®å°ºå¯¸ä¸å¯¹,å¤ªå°äº†': 'æŒ‰é’®å°ºå¯¸è¿‡å°',
            
            # æ ·å¼é—®é¢˜ä¼˜åŒ–
            r'Tabé€‰ä¸­æ€çš„æ ·å¼éœ€åŠ ç²—ä¸ºbold': 'Tabé€‰ä¸­æ€æ ·å¼ä¸å¤Ÿçªå‡º',
            r'æ ·å¼éœ€åŠ ç²—ä¸ºbold': 'æ ·å¼ä¸å¤Ÿçªå‡º',
            r'æ ·å¼éœ€åŠ ç²—': 'æ ·å¼ä¸å¤Ÿçªå‡º',
            r'éœ€åŠ ç²—ä¸ºbold': 'æ ·å¼ä¸å¤Ÿçªå‡º',
            
            # æ˜¾ç¤ºé—®é¢˜ä¼˜åŒ–
            r'å±•ç¤ºä¸å…¨': 'æ˜¾ç¤ºä¸å…¨',
            r'æ˜¾ç¤ºä¸å…¨,æˆªæ–­': 'æ˜¾ç¤ºä¸å…¨',
            r'æ–‡æ¡ˆæ˜¾ç¤ºä¸å…¨': 'æ–‡æ¡ˆæ˜¾ç¤ºä¸å…¨',
            
            # å¸ƒå±€é—®é¢˜ä¼˜åŒ–
            r'å¸ƒå±€ä¸å¯¹': 'å¸ƒå±€å¼‚å¸¸',
            r'é—´è·ä¸å¯¹': 'é—´è·å¼‚å¸¸',
            r'å¯¹é½ä¸å¯¹': 'å¯¹é½å¼‚å¸¸',
            
            # é¢œè‰²é—®é¢˜ä¼˜åŒ–
            r'é¢œè‰²ä¸å¯¹': 'é¢œè‰²å¼‚å¸¸',
            r'é¢œè‰²ä¸ç¬¦': 'é¢œè‰²ä¸åŒ¹é…',
            
            # é€šç”¨ä¼˜åŒ–
            r'å¯¼è‡´': 'ï¼Œ',
            r'æ”¾å¤§å': 'æ”¾å¤§',
        }
        
        # å…ˆåº”ç”¨ä¼˜åŒ–è§„åˆ™
        for pattern, replacement in optimizations.items():
            content = re.sub(pattern, replacement, content)
        
        # ç„¶åç§»é™¤å¸¸è§çš„å†—ä½™è¯æ±‡ï¼Œä½†ä¿ç•™æ ¸å¿ƒé—®é¢˜æè¿°
        redundant_words = ["åº”è¯¥", "éœ€è¦", "è¦", "å¯ä»¥", "å¸Œæœ›", "æœŸå¾…", "éœ€"]
        for word in redundant_words:
            content = content.replace(word, "")
        
        # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹ç¬¦å·ï¼Œä½†ä¿ç•™å¿…è¦çš„é€—å·
        content = content.replace("ã€‚", "").replace("ï¼›", "").replace(";", "")
        content = re.sub(r'ï¼Œ$', '', content)  # ç§»é™¤æœ«å°¾çš„é€—å·
        content = content.strip()
        
        # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹ç¬¦å·
        content = re.sub(r'ï¼Œ+', 'ï¼Œ', content)  # åˆå¹¶å¤šä¸ªé€—å·
        content = re.sub(r'^ï¼Œ', '', content)    # ç§»é™¤å¼€å¤´çš„é€—å·
        content = re.sub(r'ï¼Œ$', '', content)    # ç§»é™¤ç»“å°¾çš„é€—å·
        content = content.strip()
        
        # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå°è¯•è¡¥å……
        if len(content) < 3:
            content = "é—®é¢˜æè¿°"
        
        return content
    
    async def generate_solution(
        self, 
        description: str, 
        problem_type: str, 
        recommended_solutions: List[str]
    ) -> str:
        """ç”Ÿæˆè§£å†³æ–¹æ¡ˆ"""
        if recommended_solutions:
            return recommended_solutions[0]
        
        # åŸºäºæè¿°å’Œé—®é¢˜ç±»å‹ç”Ÿæˆå…·ä½“è§£å†³æ–¹æ¡ˆ
        text = description.lower()
        
        # é’ˆå¯¹ä¸åŒé—®é¢˜ç±»å‹ç”Ÿæˆå…·ä½“è§£å†³æ–¹æ¡ˆ
        if problem_type == "è§†è§‰è¿˜åŸåº¦bug":
            if "æ ·å¼" in text or "é€‰ä¸­" in text:
                return "è°ƒæ•´é€‰ä¸­çŠ¶æ€æ ·å¼ï¼Œç¡®ä¿ä¸è®¾è®¡ç¨¿ä¸€è‡´ï¼Œæå‡è§†è§‰å±‚æ¬¡æ„Ÿã€‚"
            elif "æ–‡æ¡ˆ" in text or "æ˜¾ç¤º" in text or "å±•ç¤º" in text:
                return "ä¼˜åŒ–æ–‡æ¡ˆæ˜¾ç¤ºé€»è¾‘ï¼Œè°ƒæ•´å­—ä½“å¤§å°æˆ–å®¹å™¨å°ºå¯¸ï¼Œç¡®ä¿å†…å®¹å®Œæ•´å±•ç¤ºã€‚"
            elif "é¢œè‰²" in text or "æ©˜è‰²" in text or "æŒ‰é’®" in text:
                return "ç»Ÿä¸€æŒ‰é’®é¢œè‰²è§„èŒƒï¼Œç¡®ä¿ä¸è®¾è®¡ç³»ç»Ÿä¿æŒä¸€è‡´ã€‚"
            elif "åœ†è§’" in text:
                return "ä¸ºç•Œé¢å…ƒç´ æ·»åŠ åœ†è§’è®¾è®¡ï¼Œæå‡è§†è§‰æŸ”å’Œåº¦ã€‚"
            else:
                return "è°ƒæ•´è§†è§‰å®ç°ï¼Œç¡®ä¿ä¸è®¾è®¡ç¨¿å®Œå…¨ä¸€è‡´ã€‚"
        
        elif problem_type == "äº¤äº’åŠŸèƒ½bug":
            if "å¯¼èˆª" in text or "èœå•" in text:
                return "ä¼˜åŒ–å¯¼èˆªäº¤äº’é€»è¾‘ï¼Œç¡®ä¿èœå•çŠ¶æ€åˆ‡æ¢æ­£å¸¸ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚"
            elif "åˆ‡æ¢" in text or "è¯­è¨€" in text:
                return "ä¿®å¤è¯­è¨€åˆ‡æ¢åŠŸèƒ½ï¼Œç¡®ä¿çŠ¶æ€æ­£ç¡®æ˜¾ç¤ºå’Œåˆ‡æ¢ã€‚"
            elif "ç‚¹å‡»" in text or "æ“ä½œ" in text:
                return "ä¿®å¤äº¤äº’é€»è¾‘é”™è¯¯ï¼Œç¡®ä¿æ“ä½œå“åº”æ­£å¸¸ã€‚"
            else:
                return "ä¿®å¤åŠŸèƒ½é€»è¾‘é”™è¯¯ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸è¿è¡Œã€‚"
        
        elif problem_type == "è®¾è®¡éœ€æ±‚ä¼˜åŒ–":
            return "ä¼˜åŒ–è®¾è®¡è§„èŒƒï¼Œç»Ÿä¸€è§†è§‰é£æ ¼ï¼Œæå‡æ•´ä½“ç”¨æˆ·ä½“éªŒã€‚"
        
        else:  # å†å²é—ç•™
            return "åˆ¶å®šå†å²é—®é¢˜å¤„ç†è®¡åˆ’ï¼Œé€æ­¥ä¼˜åŒ–ç›¸å…³åŠŸèƒ½æ¨¡å—ã€‚"
    
    async def fill_template(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ ¹æ®æ¨¡æ¿é…ç½®å¡«å……æ ‡å‡†åŒ–å†…å®¹"""
        try:
            if self.api_key:
                try:
                    return await self._deepseek_template_fill(description, system_types, modules, template)
                except Exception as api_error:
                    print(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {api_error}")
                    print("é™çº§åˆ°æ¨¡æ‹Ÿæ¨¡æ¿å¡«å……æ¨¡å¼")
                    return await self._mock_template_fill(description, system_types, modules, template)
            else:
                print("æœªé…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡æ¿å¡«å……æ¨¡å¼")
                return await self._mock_template_fill(description, system_types, modules, template)
        except Exception as e:
            print(f"æ¨¡æ¿å¡«å……å¤±è´¥: {e}")
            print("ä½¿ç”¨é™çº§æ¨¡æ¿å¡«å……æ¨¡å¼")
            return await self._fallback_template_fill(description, system_types, modules, template)
    
    async def _deepseek_template_fill(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨DeepSeek APIè¿›è¡Œæ¨¡æ¿å¡«å……"""
        
        # æ„å»ºæ¨¡æ¿å¡«å……æç¤ºè¯
        prompt = self._build_template_fill_prompt(description, system_types, modules, template)
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·ä½“éªŒåˆ†æå¸ˆï¼Œæ“…é•¿æ ¹æ®æ¨¡æ¿é…ç½®å°†ç”¨æˆ·åŸå£°è½¬åŒ–ä¸ºæ ‡å‡†åŒ–çš„éœ€æ±‚æ–‡æ¡£ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "max_tokens": self.max_tokens,
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                    "frequency_penalty": self.frequency_penalty,
                    "presence_penalty": self.presence_penalty,
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # è§£æJSONå“åº”
                try:
                    filled_data = json.loads(content)
                    return self._format_template_fill_result(filled_data, template)
                except json.JSONDecodeError:
                    # å¦‚æœè¿”å›çš„ä¸æ˜¯JSONï¼Œä½¿ç”¨é™çº§å¡«å……
                    return await self._mock_template_fill(description, system_types, modules, template)
            else:
                print(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
                return await self._mock_template_fill(description, system_types, modules, template)
    
    def _build_template_fill_prompt(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> str:
        """æ„å»ºæ¨¡æ¿å¡«å……æç¤ºè¯"""
        
        # è·å–æ¨¡æ¿å­—æ®µé…ç½®
        fields = template.get("config", {}).get("fields", [])
        
        # æ„å»ºå­—æ®µè¯´æ˜
        field_descriptions = []
        for field in fields:
            field_name = field.get("name", "")
            field_label = field.get("label", "")
            field_type = field.get("type", "")
            field_options = field.get("options", [])
            field_required = field.get("required", False)
            field_llm_inferred = field.get("llm_inferred", False)
            
            if field_llm_inferred:
                if field_options:
                    field_descriptions.append(f"- **{field_label}** ({field_name}): ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ - {', '.join(field_options)}")
                else:
                    field_descriptions.append(f"- **{field_label}** ({field_name}): éœ€è¦æ™ºèƒ½æ¨æ–­ç”Ÿæˆ")
            else:
                if field_options:
                    field_descriptions.append(f"- **{field_label}** ({field_name}): ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹© - {', '.join(field_options)}")
                else:
                    field_descriptions.append(f"- **{field_label}** ({field_name}): ä½¿ç”¨é»˜è®¤å€¼")
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„Bç«¯äº§å“ä½“éªŒè®¾è®¡å¸ˆï¼Œä¸“é—¨è´Ÿè´£åˆ†æå’Œç®¡ç†è®¾è®¡ä½“éªŒé—®é¢˜ã€‚è¯·æ ¹æ®ç”¨æˆ·åŸå£°æ™ºèƒ½å¡«å……è®¾è®¡ä½“éªŒé—®é¢˜æ¨¡æ¿å­—æ®µã€‚

## è¾“å…¥ä¿¡æ¯
**ç”¨æˆ·åŸå£°**ï¼š{description}
**æ‰€å±åœ°åŒº**ï¼š{', '.join(system_types)}
**å½’å±ç»ˆç«¯**ï¼š{', '.join(modules)}

## å­—æ®µé…ç½®
{chr(10).join(field_descriptions)}

## æ ¸å¿ƒåˆ†æåŸåˆ™

### 1. æ™ºèƒ½è¯†åˆ«é—®é¢˜ç±»å‹
- **è®¾è®¡éœ€æ±‚ä¼˜åŒ–**ï¼šéœ€è¦æ”¹è¿›ç°æœ‰è®¾è®¡æˆ–æ–°å¢è®¾è®¡åŠŸèƒ½
- **äº¤äº’åŠŸèƒ½bug**ï¼šäº¤äº’é€»è¾‘é”™è¯¯ã€æ“ä½œæµç¨‹é—®é¢˜  
- **è§†è§‰è¿˜åŸåº¦bug**ï¼šè®¾è®¡ç¨¿ä¸å®ç°æ•ˆæœä¸ä¸€è‡´ï¼ˆæ ·å¼ã€å¸ƒå±€ã€é¢œè‰²ã€å­—ä½“ç­‰ï¼‰
- **å†å²é—ç•™**ï¼šé•¿æœŸå­˜åœ¨çš„è®¾è®¡é—®é¢˜

### 2. ä¼˜å…ˆçº§åˆ¤æ–­æ ‡å‡†
- **P0-ç´§æ€¥**ï¼šä¸¥é‡å½±å“æ ¸å¿ƒåŠŸèƒ½ä½¿ç”¨ï¼Œç³»ç»Ÿæ— æ³•æ­£å¸¸ä½¿ç”¨
- **P1-é«˜**ï¼šå½±å“ä¸»è¦ä¸šåŠ¡æµç¨‹ï¼Œç”¨æˆ·é¢‘ç¹æŠ•è¯‰
- **P2-ä¸­**ï¼šå½±å“éƒ¨åˆ†ç”¨æˆ·ä½“éªŒä½†ä¸é˜»å¡æ ¸å¿ƒæµç¨‹
- **P3-ä½**ï¼šç»†å¾®çš„è§†è§‰è°ƒæ•´ã€æ–‡æ¡ˆä¼˜åŒ–

### 3. è§£å†³æ–¹å¼åˆ†ç±»
- **ä½“éªŒä¼˜åŒ–**ï¼šé€šè¿‡è®¾è®¡æ”¹è¿›æå‡ç”¨æˆ·ä½“éªŒ
- **éœ€æ±‚ä¼˜åŒ–**ï¼šéœ€è¦é‡æ–°å®šä¹‰æˆ–è°ƒæ•´äº§å“éœ€æ±‚

### 4. ç‰¹æ®Šæƒ…å†µå¤„ç†
**é‡è¦**ï¼šå¦‚æœç”¨æˆ·è¾“å…¥åŒ…å«è§£å†³æ–¹æ¡ˆè¯æ±‡ï¼ˆå¦‚"éœ€è¦"ã€"åº”è¯¥"ã€"å»ºè®®"ã€"è¦"ç­‰ï¼‰ï¼Œè¯·ï¼š
- å°†è§£å†³æ–¹æ¡ˆæ”¾åœ¨ `solution` å­—æ®µ
- åœ¨ `problem_description` å­—æ®µä¸­åæ¨å‡ºå®é™…é—®é¢˜
- åœ¨ `title` å­—æ®µä¸­åŸºäºé—®é¢˜è€Œéè§£å†³æ–¹æ¡ˆç”Ÿæˆæ ‡é¢˜

**ç¤ºä¾‹**ï¼š
- è¾“å…¥ï¼š"Tabé€‰ä¸­æ€çš„æ ·å¼éœ€åŠ ç²—ä¸ºbold"
- é—®é¢˜æè¿°ï¼š"Tabé€‰ä¸­æ€è§†è§‰æ ·å¼æœ‰è¯¯"
- è§£å†³æ–¹æ¡ˆï¼š"å°†Tabé€‰ä¸­æ€æ ·å¼åŠ ç²—ä¸ºboldï¼Œæå‡è§†è§‰å±‚æ¬¡å’Œç”¨æˆ·è¯†åˆ«åº¦"

## è¾“å‡ºè¦æ±‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š

{{
    "title": "æ ¹æ®é—®é¢˜æè¿°ç”Ÿæˆç®€æ´å‡†ç¡®çš„æ ‡é¢˜ï¼ˆ8-30å­—ï¼Œæ ¼å¼ï¼šã€åœ°åŒº:ç»ˆç«¯ã€‘é—®é¢˜æè¿°çš„æ ¸å¿ƒä¸»æ—¨ï¼Œæ³¨æ„ï¼šå¦‚æœè¾“å…¥æ˜¯è§£å†³æ–¹æ¡ˆï¼Œæ ‡é¢˜åº”åŸºäºåæ¨çš„é—®é¢˜è€Œéè§£å†³æ–¹æ¡ˆï¼‰",
    "region": "{', '.join(system_types)}",
    "terminal": "{', '.join(modules)}",
    "issue_type": "ä»æ¨¡æ¿é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„é—®é¢˜ç±»å‹",
    "resolution_method": "ä»æ¨¡æ¿é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„è§£å†³æ–¹å¼",
    "priority": "ä»æ¨¡æ¿é€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¼˜å…ˆçº§",
    "problem_description": "è¯¦ç»†æè¿°å…·ä½“é—®é¢˜",
    "solution": "æä¾›å…·ä½“å¯è¡Œçš„è®¾è®¡ä¼˜åŒ–æ–¹æ¡ˆï¼ŒåŒ…å«æ”¹è¿›æ€è·¯å’Œé¢„æœŸæ•ˆæœ",
    "status": "å¾…ç¡®è®¤(æœªæç»™ç ”å‘)",
    "target_version": "æœªå®š",
    "screenshots": "",
    "attachments": ""
}}

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•markdownæ ‡è®°æˆ–å…¶ä»–æ ¼å¼ã€‚
"""
        return prompt
    
    def _format_template_fill_result(self, filled_data: Dict[str, Any], template: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ¨¡æ¿å¡«å……ç»“æœ"""
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
        fields = template.get("config", {}).get("fields", [])
        result = {}
        
        for field in fields:
            field_name = field.get("name", "")
            field_default = field.get("default", "")
            field_required = field.get("required", False)
            
            # ä»å¡«å……æ•°æ®ä¸­è·å–å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
            value = filled_data.get(field_name, field_default)
            
            # å¦‚æœæ˜¯å¿…éœ€å­—æ®µä¸”æ²¡æœ‰å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if field_required and not value:
                value = field_default or ""
            
            result[field_name] = value
        
        return result
    
    async def _llm_field_matching(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å­—æ®µåŒ¹é…"""
        
        # ä»prompté…ç½®ä¸­è·å–å­—æ®µåŒ¹é…çš„prompt
        prompt_config = prompt_service.get_prompt(
            "field_matching",
            description=description,
            system_types=', '.join(system_types),
            modules=', '.join(modules)
        )
        
        try:
            print(f"ğŸ” å¼€å§‹LLMå­—æ®µåŒ¹é…è°ƒç”¨...")
            print(f"æè¿°: {description}")
            async with self.http_client as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {
                                "role": "system",
                                "content": prompt_config["system"]
                            },
                            {
                                "role": "user",
                                "content": prompt_config["user"]
                            }
                        ],
                        "max_tokens": self.max_tokens,
                        "temperature": self.temperature,
                        "top_p": self.top_p,
                        "frequency_penalty": self.frequency_penalty,
                        "presence_penalty": self.presence_penalty,
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result["choices"][0]["message"]["content"]
                    print(f"âœ… LLM APIè°ƒç”¨æˆåŠŸ!")
                    print(f"ğŸ“ LLMå“åº”å†…å®¹: {content}")
                    
                    # è§£æJSONå“åº”
                    try:
                        # æ¸…ç†å†…å®¹ï¼Œç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
                        clean_content = content.strip()
                        if clean_content.startswith('```json'):
                            clean_content = clean_content[7:]  # ç§»é™¤ ```json
                        if clean_content.endswith('```'):
                            clean_content = clean_content[:-3]  # ç§»é™¤ ```
                        clean_content = clean_content.strip()
                        
                        field_data = json.loads(clean_content)
                        print(f"ğŸ¯ LLMè¿”å›JSONæ•°æ®: {field_data}")
                        return self._format_field_matching_result(field_data, description, system_types, modules)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ LLMè¿”å›çš„ä¸æ˜¯JSONæ ¼å¼ï¼Œä½¿ç”¨æ–‡æœ¬è§£æ: {e}")
                        print(f"åŸå§‹å†…å®¹: {content}")
                        # å¦‚æœè¿”å›çš„ä¸æ˜¯JSONï¼Œä½¿ç”¨æ–‡æœ¬è§£æ
                        return await self._parse_field_matching_text(content, description, system_types, modules)
                else:
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    
        except Exception as e:
            print(f"LLMå­—æ®µåŒ¹é…APIè°ƒç”¨å¤±è´¥: {e}")
            raise e
    
    def _build_field_matching_prompt(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str]
    ) -> str:
        """æ„å»ºå­—æ®µåŒ¹é…æç¤ºè¯"""
        
        prompt = f"""ä½ æ˜¯èµ„æ·±ä½“éªŒåˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŠ½å–å¹¶åˆ†ç±»ä¸‹é¢çš„ç”¨æˆ·è¾“å…¥ï¼Œä¸”å¿…é¡»è¿”å›ä¸¥æ ¼çš„ JSONï¼ˆä¸è¦åŒ…å«markdownä»£ç å—æˆ–å¤šä½™æ–‡å­—ï¼‰ã€‚

ã€è¾“å…¥ã€‘
åé¦ˆå†…å®¹ï¼š{description}
åœ°åŒºï¼š{', '.join(system_types)}
ç»ˆç«¯ï¼š{', '.join(modules)}

ã€æŠ½å–è¦æ±‚ï¼ˆæå…¶é‡è¦ï¼‰ã€‘
1) é—®é¢˜/æ–¹æ¡ˆè¾¹ç•Œï¼š
   - è‹¥åŒä¸€æ®µä¸­æ—¢å«"é—®é¢˜"åˆå«"æ–¹æ¡ˆ"ï¼ŒæŒ‰"é—®é¢˜åœ¨å‰ã€åŠ¨ä½œåœ¨å"æ‹†åˆ†ï¼š
     * å½¢å¦‚"Xæœ‰é—®é¢˜ï¼Œâ€¦å°†/æŠŠ/éœ€è¦/ç»Ÿä¸€/è°ƒæ•´/æ”¹ä¸º/ä¼˜åŒ–â€¦"â†’ é€—å·å‰ä¸º problem_descriptionï¼Œé€—å·åä¸º solution
     * å½¢å¦‚"Xé—®é¢˜æè¿°ã€‚1. è§£å†³æ–¹æ¡ˆ1ï¼›2. è§£å†³æ–¹æ¡ˆ2"â†’ å¥å·å‰ä¸º problem_descriptionï¼Œç¼–å·åˆ—è¡¨ä¸º solution
     * å½¢å¦‚"Xé—®é¢˜æè¿°ï¼Œå¯¼è‡´Yé—®é¢˜ã€‚è§£å†³æ–¹æ¡ˆæè¿°"â†’ ç¬¬ä¸€ä¸ªå¥å·å‰ä¸º problem_descriptionï¼Œå¥å·åä¸º solution
   - è‹¥åªæœ‰é—®é¢˜ï¼šä¿æŒåŸæ„ï¼Œç”Ÿæˆç®€æ´çš„åŠ¨ä½œå‹æ–¹æ¡ˆï¼ˆä»¥åŠ¨è¯å¼€å¤´ï¼‰ï¼Œä¸è¦è‡†é€ ä¸åŸæ„æ— å…³å†…å®¹ã€‚
   - è‹¥åªæœ‰æ–¹æ¡ˆï¼šä¿ç•™æ–¹æ¡ˆåŸè¯ï¼ŒåŒæ—¶æ ¹æ®æ–¹æ¡ˆåæ¨ä¸€å¥ç®€çŸ­çš„é—®é¢˜æè¿°ï¼ˆç—‡çŠ¶/ç°è±¡ï¼‰ï¼Œé¿å…æ”¹å˜ç”¨æˆ·æ„å›¾ã€‚
   - å°½é‡ä¿ç•™ç”¨æˆ·åŸè¯ï¼›æ¯é¡¹ä¸ºä¸€å¥å®Œæ•´ä¸­æ–‡å¥å­ï¼Œä»¥"ã€‚"ç»“å°¾ï¼›ä¸è¦åŠ å…¥"å»ºè®®"å‰ç¼€ï¼Œé™¤éåŸæ–‡å°±æœ‰ã€‚
   - ç¦æ­¢ç©ºæ³›æªè¾ï¼ˆå¦‚"ä¼˜åŒ–ä½“éªŒ"ï¼‰å•ç‹¬å‡ºç°ï¼›è‹¥å¿…é¡»è¡¥å…¨ï¼Œéœ€ç»“åˆè¾“å…¥é‡Œçš„å…·ä½“å¯¹è±¡ä¸å±æ€§ã€‚

2) åˆ†ç±»ä¸ä¼˜å…ˆçº§ï¼š
   - è§†è§‰ä¸è®¾è®¡ç¨¿/è§„èŒƒä¸ä¸€è‡´ã€æ ·å¼/å¯¹é½/é—´è·/è‰²å€¼/è¿˜åŸåº¦ â†’ è§†è§‰è¿˜åŸåº¦bug
   - åŠŸèƒ½/äº¤äº’/æµç¨‹å¼‚å¸¸ã€ä¸å¯ç”¨ã€æŠ¥é”™ â†’ äº¤äº’åŠŸèƒ½bug
   - éœ€è¦æ–°å¢/è°ƒæ•´è®¾è®¡ä¸äº§å“æ–¹æ¡ˆ â†’ è®¾è®¡éœ€æ±‚ä¼˜åŒ–
   - å…¶ä»–ä¸å±äºä»¥ä¸Šçš„ â†’ å†å²é—ç•™
   - ä¼˜å…ˆçº§å‚ç…§ï¼šå´©æºƒ/æ”¯ä»˜/æ ¸å¿ƒé˜»æ–­=P0ï¼›åŠŸèƒ½å¼‚å¸¸=P1ï¼›ç•Œé¢/ä½“éªŒé—®é¢˜=P2ï¼›å»ºè®®å‹=P3ã€‚

ã€è¾“å‡ºJSONç»“æ„ï¼ˆå¿…é¡»å®Œæ•´ä¸”ä»…æ­¤ç»“æ„ï¼‰ã€‘
{
  "issue_type": "è®¾è®¡éœ€æ±‚ä¼˜åŒ–/äº¤äº’åŠŸèƒ½bug/è§†è§‰è¿˜åŸåº¦bug/å†å²é—ç•™",
  "resolution_method": "ä½“éªŒä¼˜åŒ–/éœ€æ±‚ä¼˜åŒ–",
  "priority": "P0-ç´§æ€¥/P1-é«˜/P2-ä¸­/P3-ä½",
  "confidence": 0.80,
  "reasoning": "ä¸è¶…è¿‡30å­—çš„åˆ¤å®šç†ç”±",
  "problem_description": "ç²¾å‡†çš„é—®é¢˜ä¸€å¥è¯ï¼Œä¿æŒç”¨æˆ·åŸæ„ï¼Œä¸è¦æ·»åŠ åœ°åŒºã€æ¨¡å—ç­‰èƒŒæ™¯ä¿¡æ¯ï¼Œå¥æœ«åŠ ã€‚",
  "solution": "åŠ¨ä½œå‹è§£å†³æ–¹æ¡ˆä¸€å¥æˆ–å¤šå¥ï¼Œå¥æœ«åŠ ã€‚"
}

ä»…è¾“å‡º JSONã€‚"""
        return prompt
    
    def _post_process_llm_result(self, field_data: Dict[str, Any], description: str) -> Dict[str, Any]:
        """åå¤„ç†LLMç»“æœï¼Œçº æ­£è¯†åˆ«é”™è¯¯"""
        
        print(f"ğŸ” å¼€å§‹åå¤„ç†æ£€æŸ¥...")
        print(f"åŸå§‹è¾“å…¥: {description}")
        print(f"LLMè¿”å›æ•°æ®: {field_data}")
        
        # è§£å†³æ–¹æ¡ˆè¯†åˆ«å…³é”®è¯
        solution_keywords = [
            "éœ€", "éœ€è¦", "åº”è¯¥", "å»ºè®®", "è¦", "å¯ä»¥",
            "åŠ ç²—", "é¢œè‰²", "å¤§å°", "ä½ç½®", "å¢åŠ ", "æ·»åŠ ", "ä¼˜åŒ–", "è°ƒæ•´"
        ]
        
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºè§£å†³æ–¹æ¡ˆ
        is_solution = any(keyword in description for keyword in solution_keywords)
        print(f"æ˜¯å¦ä¸ºè§£å†³æ–¹æ¡ˆ: {is_solution}")
        
        if is_solution:
            # å¦‚æœè¯†åˆ«ä¸ºè§£å†³æ–¹æ¡ˆï¼Œä½†LLMå°†å…¶æ”¾åœ¨äº†problem_descriptionä¸­
            problem_desc = field_data.get("problem_description", "")
            solution = field_data.get("solution", "")
            
            print(f"å½“å‰problem_description: {problem_desc}")
            print(f"å½“å‰solution: {solution}")
            print(f"åŸå§‹è¾“å…¥åœ¨problem_descriptionä¸­: {description in problem_desc}")
            print(f"åŸå§‹è¾“å…¥åœ¨solutionä¸­: {description in solution}")
            
            # å¦‚æœåŸå§‹è¾“å…¥åœ¨problem_descriptionä¸­ï¼Œè¯´æ˜è¯†åˆ«é”™è¯¯
            if description in problem_desc and description not in solution:
                print(f"ğŸ”§ æ£€æµ‹åˆ°è¯†åˆ«é”™è¯¯ï¼Œæ­£åœ¨çº æ­£...")
                
                # å°†åŸå§‹è¾“å…¥ç§»åˆ°solutionå­—æ®µ
                field_data["solution"] = description
                
                # æ ¹æ®è§£å†³æ–¹æ¡ˆåæ¨é—®é¢˜æè¿°
                inferred_problem = self._infer_problem_from_solution(description)
                field_data["problem_description"] = inferred_problem
                
                print(f"âœ… çº æ­£åsolution: {field_data['solution']}")
                print(f"âœ… çº æ­£åproblem_description: {field_data['problem_description']}")
            else:
                print(f"â„¹ï¸ æ— éœ€çº æ­£ï¼Œè¯†åˆ«æ­£ç¡®")
        else:
            print(f"â„¹ï¸ ä¸æ˜¯è§£å†³æ–¹æ¡ˆï¼Œæ— éœ€åå¤„ç†")
        
        # å¤„ç†æ··åˆè¾“å…¥çš„æƒ…å†µ
        field_data = self._process_mixed_input(field_data, description)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„é—®é¢˜æè¿°æ¸…ç†é€»è¾‘
        from app.utils.problem_description_utils import ProblemDescriptionUtils
        problem_desc = field_data.get("problem_description", "")
        if problem_desc:
            field_data["problem_description"] = ProblemDescriptionUtils.clean_problem_description(problem_desc)
        
        # è‹¥solutionçœ‹èµ·æ¥ä»æ˜¯"é—®é¢˜åˆ—è¡¨"ï¼Œæ”¹å†™ä¸ºåŠ¨ä½œå‹æ–¹æ¡ˆ
        try:
            sol = field_data.get("solution", "") or ""
            if self._looks_like_problem_list(sol):
                field_data["solution"] = self._rewrite_problem_list_to_actions(sol)
        except Exception:
            pass
        return field_data

    def _process_mixed_input(self, field_data: Dict[str, Any], description: str) -> Dict[str, Any]:
        """å¤„ç†æ··åˆè¾“å…¥ï¼ˆé—®é¢˜+è§£å†³æ–¹æ¡ˆï¼‰çš„æ™ºèƒ½æ‹†åˆ†"""
        from app.utils.problem_description_utils import ProblemDescriptionUtils
        
        # ä½¿ç”¨ç»Ÿä¸€çš„é—®é¢˜æè¿°ç”Ÿæˆé€»è¾‘
        problem_text, solution_text = ProblemDescriptionUtils.split_problem_and_solution(description)
        
        if problem_text and solution_text:
            print(f"ğŸ”§ æ£€æµ‹åˆ°æ··åˆè¾“å…¥ï¼Œæ­£åœ¨æ™ºèƒ½æ‹†åˆ†...")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ¶¦è‰²é€»è¾‘
            enriched = ProblemDescriptionUtils.enrich_problem_description(problem_text, solution_text, description)
            
            # æ›´æ–°å­—æ®µæ•°æ®
            if enriched['problem']:
                field_data["problem_description"] = enriched['problem']
            if enriched['solution']:
                field_data["solution"] = enriched['solution']
            
            print(f"âœ… æ‹†åˆ†åproblem_description: {field_data['problem_description']}")
            print(f"âœ… æ‹†åˆ†åsolution: {field_data['solution']}")
        
        return field_data

    def _looks_like_problem_list(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ›´åƒé—®é¢˜ç°è±¡åˆ—è¡¨è€ŒéåŠ¨ä½œå‹æ–¹æ¡ˆ"""
        if not text:
            return False
        s = str(text).strip()
        import re
        issue_hints = re.findall(r"(æœ‰é—®é¢˜|ä¸ä¸€è‡´|å¼‚å¸¸|é”™è¯¯|é‡å |é®æŒ¡|ä¸åˆ°è¾¹|åˆ°é¡¶|æ˜¾ç¤ºä¸å…¨|å­˜åœ¨|æ˜¯)", s)
        action_hints = re.findall(r"(å°†|æŠŠ|éœ€è¦|ç»Ÿä¸€|è°ƒæ•´|æ”¹ä¸º|æ”¹æˆ|ä¼˜åŒ–|ä¿®å¤|ä¿®æ”¹|æ›´æ”¹)", s)
        list_like = bool(re.search(r"\d+[^\n]*[ã€‚ï¼›;ï¼Œ,]", s) or re.search(r"\n", s))
        return (len(issue_hints) > len(action_hints)) and list_like

    def _rewrite_problem_list_to_actions(self, text: str) -> str:
        """å°†é—®é¢˜åˆ—è¡¨æ”¹å†™ä¸ºåŠ¨ä½œå‹æ–¹æ¡ˆï¼Œå°½é‡ä¸æ”¹å˜åŸæ„"""
        import re
        raw = re.sub(r"^[^\n:ï¼š]*[:ï¼š]\s*", "", str(text)).strip()
        items = [p.strip() for p in re.split(r"[\n\s]*[ï¼ˆ(]?\d+[ã€\.ï¼\)ï¼‰]\s*", raw) if p.strip()]
        actions: list[str] = []
        for p in items:
            if re.search(r"åº•éƒ¨æ¡†", p) and re.search(r"åˆ°è¾¹", p):
                actions.append("åº•éƒ¨æ¡†å·¦å³å¯¹é½è¾¹ç¼˜ï¼Œé¡¶éƒ¨ä¸é¡¶åˆ°é¡¶")
                continue
            if re.search(r"(é¡¶éƒ¨|ä¸Šæ–¹).*æç¤º", p) and re.search(r"(é‡å |é®æŒ¡)", p):
                actions.append("è°ƒæ•´æç¤ºä¸å›¾ç‰‡/æ–‡å­—çš„å±‚çº§æˆ–é—´è·ï¼Œé¿å…é‡å ")
                continue
            if re.search(r"(æ–‡å­—|æ–‡æ¡ˆ).*åº•è‰²|èƒŒæ™¯", p):
                actions.append("ç§»é™¤æ–‡å­—åŒºåº•è‰²æˆ–æŒ‰è®¾è®¡è®¾ä¸ºæ­£ç¡®åº•è‰²")
                continue
        if not actions:
            return "é’ˆå¯¹ä¸Šè¿°é—®é¢˜é€é¡¹ä¼˜åŒ–ï¼Œç¡®ä¿è§†è§‰ä¸äº¤äº’ç¬¦åˆè®¾è®¡é¢„æœŸã€‚"
        return "ï¼›".join(actions) + "ã€‚"
    
    def _infer_problem_from_solution(self, solution: str) -> str:
        """æ ¹æ®è§£å†³æ–¹æ¡ˆåæ¨é—®é¢˜æè¿°"""
        
        # è§£å†³æ–¹æ¡ˆåˆ°é—®é¢˜çš„æ˜ å°„
        solution_problem_mapping = {
            "Tabé€‰ä¸­æ€çš„æ ·å¼éœ€åŠ ç²—ä¸ºbold": "Tabé€‰ä¸­æ€è§†è§‰å±‚æ¬¡ä¸å¤Ÿçªå‡ºï¼Œç”¨æˆ·éš¾ä»¥å¿«é€Ÿè¯†åˆ«å½“å‰æ‰€åœ¨ä½ç½®ï¼Œå½±å“å¯¼èˆªæ•ˆç‡å’Œæ“ä½œä½“éªŒ",
            "å»ºè®®å¢åŠ è¿›åº¦æ¡æ˜¾ç¤º": "æ“ä½œè¿‡ç¨‹ç¼ºä¹è¿›åº¦åé¦ˆï¼Œç”¨æˆ·æ— æ³•é¢„ä¼°ç­‰å¾…æ—¶é—´ï¼Œå½±å“æ“ä½œä¿¡å¿ƒ",
            "æŒ‰é’®åº”è¯¥åŠ ç²—æ˜¾ç¤º": "æŒ‰é’®è§†è§‰å±‚æ¬¡ä¸å¤Ÿçªå‡ºï¼Œç”¨æˆ·éš¾ä»¥å¿«é€Ÿè¯†åˆ«å½“å‰å¯æ“ä½œå…ƒç´ ",
            "éœ€è¦æ·»åŠ ç¡®è®¤å¼¹çª—": "å…³é”®æ“ä½œç¼ºä¹äºŒæ¬¡ç¡®è®¤æœºåˆ¶ï¼Œå­˜åœ¨è¯¯æ“ä½œé£é™©",
            "å»ºè®®ä¼˜åŒ–åŠ è½½åŠ¨ç”»": "åŠ è½½è¿‡ç¨‹ç¼ºä¹è§†è§‰åé¦ˆï¼Œç”¨æˆ·æ— æ³•æ„ŸçŸ¥ç³»ç»ŸçŠ¶æ€"
        }
        
        # ç›´æ¥åŒ¹é…
        if solution in solution_problem_mapping:
            return solution_problem_mapping[solution]
        
        # æ¨¡ç³ŠåŒ¹é…
        if "åŠ ç²—" in solution and "Tab" in solution:
            return "Tabé€‰ä¸­æ€è§†è§‰å±‚æ¬¡ä¸å¤Ÿçªå‡ºï¼Œç”¨æˆ·éš¾ä»¥å¿«é€Ÿè¯†åˆ«å½“å‰æ‰€åœ¨ä½ç½®ï¼Œå½±å“å¯¼èˆªæ•ˆç‡å’Œæ“ä½œä½“éªŒ"
        elif "è¿›åº¦æ¡" in solution:
            return "æ“ä½œè¿‡ç¨‹ç¼ºä¹è¿›åº¦åé¦ˆï¼Œç”¨æˆ·æ— æ³•é¢„ä¼°ç­‰å¾…æ—¶é—´ï¼Œå½±å“æ“ä½œä¿¡å¿ƒ"
        elif "åŠ ç²—" in solution and "æŒ‰é’®" in solution:
            return "æŒ‰é’®è§†è§‰å±‚æ¬¡ä¸å¤Ÿçªå‡ºï¼Œç”¨æˆ·éš¾ä»¥å¿«é€Ÿè¯†åˆ«å½“å‰å¯æ“ä½œå…ƒç´ "
        elif "ç¡®è®¤å¼¹çª—" in solution:
            return "å…³é”®æ“ä½œç¼ºä¹äºŒæ¬¡ç¡®è®¤æœºåˆ¶ï¼Œå­˜åœ¨è¯¯æ“ä½œé£é™©"
        elif "åŠ è½½åŠ¨ç”»" in solution:
            return "åŠ è½½è¿‡ç¨‹ç¼ºä¹è§†è§‰åé¦ˆï¼Œç”¨æˆ·æ— æ³•æ„ŸçŸ¥ç³»ç»ŸçŠ¶æ€"
        else:
            # é€šç”¨åæ¨é€»è¾‘
            return f"å½“å‰è®¾è®¡å­˜åœ¨ç”¨æˆ·ä½“éªŒé—®é¢˜ï¼Œéœ€è¦æŒ‰ç…§'{solution}'è¿›è¡Œä¼˜åŒ–æ”¹è¿›"
    
    def _format_field_matching_result(
        self, 
        field_data: Dict[str, Any], 
        description: str, 
        system_types: List[str], 
        modules: List[str]
    ) -> Dict[str, Any]:
        """æ ¼å¼åŒ–å­—æ®µåŒ¹é…ç»“æœ"""
        
        # åå¤„ç†é€»è¾‘ï¼šçº æ­£LLMçš„è¯†åˆ«é”™è¯¯
        field_data = self._post_process_llm_result(field_data, description)
        
        # éªŒè¯å­—æ®µå€¼çš„æœ‰æ•ˆæ€§
        valid_issue_types = ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "äº¤äº’åŠŸèƒ½bug", "è§†è§‰è¿˜åŸåº¦bug", "å†å²é—ç•™"]
        valid_resolution_methods = ["ä½“éªŒä¼˜åŒ–", "éœ€æ±‚ä¼˜åŒ–"]
        valid_priorities = ["P0-ç´§æ€¥", "P1-é«˜", "P2-ä¸­", "P3-ä½"]
        
        issue_type = field_data.get("issue_type", "è®¾è®¡éœ€æ±‚ä¼˜åŒ–")
        if issue_type not in valid_issue_types:
            issue_type = "è®¾è®¡éœ€æ±‚ä¼˜åŒ–"
        
        resolution_method = field_data.get("resolution_method", "ä½“éªŒä¼˜åŒ–")
        if resolution_method not in valid_resolution_methods:
            resolution_method = "ä½“éªŒä¼˜åŒ–"
        
        priority = field_data.get("priority", "P2-ä¸­")
        if priority not in valid_priorities:
            priority = "P2-ä¸­"
        
        confidence = field_data.get("confidence", 0.8)
        if not isinstance(confidence, (int, float)) or confidence < 0 or confidence > 1:
            confidence = 0.8
        
        # æ™ºèƒ½è§£å†³æ–¹æ¡ˆæ¨è
        solutions = {
            "è®¾è®¡éœ€æ±‚ä¼˜åŒ–": [
                "ä¼˜åŒ–ç”¨æˆ·ç•Œé¢è®¾è®¡ï¼Œæå‡è§†è§‰æ•ˆæœå’Œç”¨æˆ·ä½“éªŒ",
                "æ”¹è¿›äº¤äº’è®¾è®¡ï¼Œç®€åŒ–æ“ä½œæµç¨‹",
                "ç»Ÿä¸€è®¾è®¡è§„èŒƒï¼Œä¿æŒç•Œé¢é£æ ¼ä¸€è‡´æ€§"
            ],
            "äº¤äº’åŠŸèƒ½bug": [
                "ä¿®å¤äº¤äº’é€»è¾‘é”™è¯¯ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸è¿è¡Œ",
                "å®Œå–„å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§",
                "å¢åŠ åŠŸèƒ½æµ‹è¯•è¦†ç›–ï¼Œé¢„é˜²ç±»ä¼¼é—®é¢˜å†æ¬¡å‘ç”Ÿ"
            ],
            "è§†è§‰è¿˜åŸåº¦bug": [
                "è°ƒæ•´è§†è§‰å®ç°ï¼Œç¡®ä¿ä¸è®¾è®¡ç¨¿ä¸€è‡´",
                "ä¼˜åŒ–æ¸²æŸ“æ•ˆæœï¼Œæå‡è§†è§‰è´¨é‡",
                "å»ºç«‹è®¾è®¡è¿˜åŸåº¦æ£€æŸ¥æœºåˆ¶"
            ],
            "å†å²é—ç•™": [
                "åˆ¶å®šå†å²é—®é¢˜å¤„ç†è®¡åˆ’ï¼Œé€æ­¥ä¼˜åŒ–",
                "é‡æ„ç›¸å…³æ¨¡å—ï¼Œæå‡ä»£ç è´¨é‡",
                "å»ºç«‹é—®é¢˜è·Ÿè¸ªæœºåˆ¶ï¼Œé¿å…é—®é¢˜ç§¯ç´¯"
            ]
        }
        
        # æ™ºèƒ½å¤„ç†æ–¹å¼
        processing_methods = {
            "P0-ç´§æ€¥": {
                "method": resolution_method,
                "assignee": "å¼€å‘å›¢é˜Ÿ" if resolution_method == "éœ€æ±‚ä¼˜åŒ–" else "è®¾è®¡å›¢é˜Ÿ",
                "timeline": "1-2ä¸ªå·¥ä½œæ—¥",
                "escalation": "éœ€è¦ç«‹å³ä¸ŠæŠ¥"
            },
            "P1-é«˜": {
                "method": resolution_method,
                "assignee": "å¼€å‘å›¢é˜Ÿ" if resolution_method == "éœ€æ±‚ä¼˜åŒ–" else "è®¾è®¡å›¢é˜Ÿ",
                "timeline": "3-5ä¸ªå·¥ä½œæ—¥",
                "escalation": "æŒ‰è®¡åˆ’å¤„ç†"
            },
            "P2-ä¸­": {
                "method": resolution_method,
                "assignee": "å¼€å‘å›¢é˜Ÿ" if resolution_method == "éœ€æ±‚ä¼˜åŒ–" else "è®¾è®¡å›¢é˜Ÿ",
                "timeline": "1-2å‘¨",
                "escalation": "æŒ‰è®¡åˆ’å¤„ç†"
            },
            "P3-ä½": {
                "method": resolution_method,
                "assignee": "å¼€å‘å›¢é˜Ÿ" if resolution_method == "éœ€æ±‚ä¼˜åŒ–" else "è®¾è®¡å›¢é˜Ÿ",
                "timeline": "ä¸‹ä¸ªç‰ˆæœ¬",
                "escalation": "ä¸‹ä¸ªç‰ˆæœ¬"
            }
        }
        
        # æ™ºèƒ½å½±å“åˆ†æ
        impact_analysis = {
            "è®¾è®¡éœ€æ±‚ä¼˜åŒ–": "å½±å“ç”¨æˆ·è§†è§‰ä½“éªŒå’Œç•Œé¢ç¾è§‚åº¦ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·æ»¡æ„åº¦ä¸‹é™",
            "äº¤äº’åŠŸèƒ½bug": "å½±å“ç”¨æˆ·æ“ä½œæµç¨‹ï¼Œå¯èƒ½å¯¼è‡´åŠŸèƒ½æ— æ³•æ­£å¸¸ä½¿ç”¨",
            "è§†è§‰è¿˜åŸåº¦bug": "å½±å“è®¾è®¡ä¸€è‡´æ€§ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·ä½“éªŒä¸é¢„æœŸä¸ç¬¦",
            "å†å²é—ç•™": "å½±å“ç³»ç»Ÿæ•´ä½“è´¨é‡ï¼Œå¯èƒ½å¯¼è‡´æŠ€æœ¯å€ºåŠ¡ç§¯ç´¯"
        }
        
        return {
            "predictedType": issue_type,
            "priority": priority,
            "confidence": confidence,
            "impact": impact_analysis.get(issue_type, "å½±å“ç”¨æˆ·ä½“éªŒï¼Œéœ€è¦åŠæ—¶å¤„ç†è§£å†³"),
            "recommendedSolutions": solutions.get(issue_type, ["æ ¹æ®é—®é¢˜å…·ä½“æƒ…å†µåˆ¶å®šé’ˆå¯¹æ€§è§£å†³æ–¹æ¡ˆ"]),
            "estimatedTime": processing_methods[priority]["timeline"],
            "relatedModules": modules,
            "processingMethod": processing_methods[priority],
            "acceptanceCriteria": [
                "é—®é¢˜å¾—åˆ°æœ‰æ•ˆè§£å†³ï¼ŒåŠŸèƒ½æ­£å¸¸è¿è¡Œ",
                "ç”¨æˆ·ä½“éªŒæ˜æ˜¾æ”¹å–„ï¼Œæ“ä½œæµç•…",
                "æ— æ–°çš„ç›¸å…³é—®é¢˜äº§ç”Ÿï¼Œç³»ç»Ÿç¨³å®š",
                "ç¬¦åˆäº§å“è®¾è®¡è§„èŒƒå’Œç”¨æˆ·æœŸæœ›"
            ],
            "analysisConfidence": confidence,
            "llm_reasoning": field_data.get("reasoning", "åŸºäºLLMæ™ºèƒ½åˆ†æ"),
            # æ·»åŠ åå¤„ç†åçš„å­—æ®µ
            "problem_description": field_data.get("problem_description", description),
            "solution": field_data.get("solution", solutions.get(issue_type, ["æ ¹æ®é—®é¢˜å…·ä½“æƒ…å†µåˆ¶å®šé’ˆå¯¹æ€§è§£å†³æ–¹æ¡ˆ"])[0])
        }
    
    async def _parse_field_matching_text(
        self, 
        content: str, 
        description: str, 
        system_types: List[str], 
        modules: List[str]
    ) -> Dict[str, Any]:
        """è§£ææ–‡æœ¬æ ¼å¼çš„å­—æ®µåŒ¹é…ç»“æœ"""
        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘ï¼Œå›é€€åˆ°å…³é”®è¯åŒ¹é…
        return await self._fallback_analysis(description, system_types, modules, {})
    
    async def _mock_template_fill(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ¨¡æ¿å¡«å……ï¼ˆå½“APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        
        # åŸºäºå…³é”®è¯çš„æ™ºèƒ½åˆ†æ
        text = description.lower()
        
        # é—®é¢˜ç±»å‹é¢„æµ‹ - æ ¹æ®æ¨¡æ¿é€‰é¡¹è¿›è¡Œåˆ†ç±»
        issue_type = "è®¾è®¡éœ€æ±‚ä¼˜åŒ–"
        if any(keyword in text for keyword in ["è®¾è®¡", "ç•Œé¢", "å¸ƒå±€", "ç¾è§‚", "é¢œè‰²", "æ ·å¼", "å¤–è§‚", "è§†è§‰", "UI", "UX"]):
            issue_type = "è®¾è®¡éœ€æ±‚ä¼˜åŒ–"
        elif any(keyword in text for keyword in ["äº¤äº’", "æ“ä½œ", "ç‚¹å‡»", "æŒ‰é’®", "åŠŸèƒ½", "æ— æ³•", "ä¸èƒ½", "é”™è¯¯", "å¼‚å¸¸", "bug"]):
            issue_type = "äº¤äº’åŠŸèƒ½bug"
        elif any(keyword in text for keyword in ["è¿˜åŸ", "å®ç°", "ä¸ä¸€è‡´", "åå·®", "æ•ˆæœ", "æ˜¾ç¤º", "æ¸²æŸ“"]):
            issue_type = "è§†è§‰è¿˜åŸåº¦bug"
        elif any(keyword in text for keyword in ["å†å²", "é—ç•™", "è€", "æ—§", "ä¸€ç›´", "é•¿æœŸ", "å­˜åœ¨"]):
            issue_type = "å†å²é—ç•™"
        
        # è§£å†³æ–¹å¼é¢„æµ‹
        resolution_method = "ä½“éªŒä¼˜åŒ–"
        if issue_type in ["è®¾è®¡éœ€æ±‚ä¼˜åŒ–", "è§†è§‰è¿˜åŸåº¦bug"]:
            resolution_method = "ä½“éªŒä¼˜åŒ–"
        else:
            resolution_method = "éœ€æ±‚ä¼˜åŒ–"
        
        # ä¼˜å…ˆçº§é¢„æµ‹
        priority = "P2-ä¸­"
        if any(keyword in text for keyword in ["å´©æºƒ", "é—ªé€€", "æ— æ³•ç™»å½•", "æ•°æ®ä¸¢å¤±", "æ”¯ä»˜", "äº¤æ˜“", "æ ¸å¿ƒ", "ç´§æ€¥", "ä¸¥é‡", "å¿«ç‚¹", "å°½å¿«"]):
            priority = "P0-ç´§æ€¥"
        elif any(keyword in text for keyword in ["åŠŸèƒ½", "å¼‚å¸¸", "é”™è¯¯", "bug", "å¤±æ•ˆ", "ä¸å·¥ä½œ", "æ•…éšœ"]):
            priority = "P1-é«˜"
        elif any(keyword in text for keyword in ["ç•Œé¢ä¼˜åŒ–", "ä½“éªŒæ”¹è¿›", "å»ºè®®", "å¸Œæœ›", "æœŸå¾…", "ä¼˜åŒ–", "ç¾åŒ–", "æ”¹è¿›"]):
            priority = "P3-ä½"
        
        # ç”Ÿæˆæ ‡é¢˜
        title = await self.generate_title(description, issue_type, system_types, modules)
        
        # ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
        solution = await self.generate_solution(description, issue_type, [])
        
        # æ„å»ºå¡«å……ç»“æœ
        result = {
            "title": title,
            "region": ', '.join(system_types),
            "terminal": ', '.join(modules),
            "issue_type": issue_type,
            "resolution_method": resolution_method,
            "priority": priority,
            "problem_description": description,
            "solution": solution,
            "status": "å¾…ç¡®è®¤(æœªæç»™ç ”å‘)",
            "target_version": "æœªå®š",
            "screenshots": "",
            "attachments": ""
        }
        
        return result
    
    async def _fallback_template_fill(
        self, 
        description: str, 
        system_types: List[str], 
        modules: List[str], 
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é™çº§æ¨¡æ¿å¡«å……ï¼ˆå½“æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        print("ä½¿ç”¨é™çº§æ¨¡æ¿å¡«å……æ¨¡å¼")
        
        return {
            "title": "è®¾è®¡ä½“éªŒé—®é¢˜åé¦ˆ",
            "region": ', '.join(system_types),
            "terminal": ', '.join(modules),
            "issue_type": "è®¾è®¡éœ€æ±‚ä¼˜åŒ–",
            "resolution_method": "ä½“éªŒä¼˜åŒ–",
            "priority": "P2-ä¸­",
            "problem_description": description,
            "solution": "è¯·è¯¦ç»†æè¿°é—®é¢˜ç°è±¡å’ŒæœŸæœ›çš„è§£å†³æ–¹æ¡ˆ",
            "status": "å¾…ç¡®è®¤(æœªæç»™ç ”å‘)",
            "target_version": "æœªå®š",
            "screenshots": "",
            "attachments": ""
        }

    async def analyze_original_sound(
        self,
        user_input: str,
        source_language: str,
        target_language: str,
        template: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·åŸå£°"""
        print(f"ğŸ¯ å¼€å§‹åˆ†æç”¨æˆ·åŸå£°: {user_input[:50]}...")
        
        try:
            # ä½¿ç”¨åŸå£°åˆ†ææç¤ºè¯
            prompt_config = prompt_service.get_prompt("original_sound_analysis")
            
            if not prompt_config or not prompt_config.get("system") or not prompt_config.get("user"):
                print("âš ï¸ æœªæ‰¾åˆ°åŸå£°åˆ†ææç¤ºè¯é…ç½®ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                return await self._fallback_original_sound_analysis(
                    user_input, source_language, target_language
                )
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": prompt_config["system"]},
                    {"role": "user", "content": prompt_config["user"].format(
                        user_input=user_input,
                        source_language=source_language,
                        target_language=target_language
                    )}
                ],
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "top_p": self.top_p,
                "frequency_penalty": self.frequency_penalty,
                "presence_penalty": self.presence_penalty
            }
            
            print(f"ğŸ“¤ å‘é€åŸå£°åˆ†æè¯·æ±‚åˆ°DeepSeek API")
            
            # å‘é€è¯·æ±‚
            response = await self.http_client.post(
                f"{self.base_url}/chat/completions",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json=request_data
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                print(f"âœ… DeepSeek APIåŸå£°åˆ†ææˆåŠŸ")
                
                # è§£æå“åº”
                analysis_result = await self._parse_original_sound_response(content)
                return analysis_result
            else:
                print(f"âŒ DeepSeek APIåŸå£°åˆ†æå¤±è´¥: {response.status_code}")
                return await self._fallback_original_sound_analysis(
                    user_input, source_language, target_language
                )
                
        except Exception as e:
            print(f"âŒ åŸå£°åˆ†æå¼‚å¸¸: {str(e)}")
            return await self._fallback_original_sound_analysis(
                user_input, source_language, target_language
            )

    async def transcribe_audio(
        self,
        audio_file_path: str,
        source_language: str
    ) -> str:
        """è¯­éŸ³è¯†åˆ«è½¬æ–‡æœ¬"""
        print(f"ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«: {audio_file_path}")
        
        try:
            # æ£€æŸ¥OpenAI APIå¯†é’¥
            if not self.openai_api_key:
                print("âš ï¸ æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ç»“æœ")
                return await self._mock_transcribe_audio(audio_file_path, source_language)
            
            # ä½¿ç”¨OpenAI Whisper APIè¿›è¡Œè¯­éŸ³è¯†åˆ«
            return await self._whisper_transcribe(audio_file_path, source_language)
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
            return await self._mock_transcribe_audio(audio_file_path, source_language)
    
    async def _whisper_transcribe(self, audio_file_path: str, source_language: str) -> str:
        """ä½¿ç”¨OpenAI Whisper APIè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            import openai
            
            # è®¾ç½®OpenAI APIå¯†é’¥
            openai.api_key = self.openai_api_key
            
            # è¯­è¨€æ˜ å°„
            language_map = {
                "è‹±æ–‡": "en",
                "è¥¿ç­ç‰™è¯­": "es", 
                "è‘¡è„ç‰™è¯­": "pt",
                "ä¸­æ–‡": "zh"
            }
            
            whisper_language = language_map.get(source_language, "auto")
            
            print(f"ğŸ”Š ä½¿ç”¨Whisper APIè¯†åˆ«è¯­éŸ³ï¼Œè¯­è¨€: {whisper_language}")
            
            # æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
            with open(audio_file_path, "rb") as audio_file:
                # è°ƒç”¨Whisper API
                transcript = await openai.Audio.atranscribe(
                    model="whisper-1",
                    file=audio_file,
                    language=whisper_language if whisper_language != "auto" else None,
                    response_format="text"
                )
                
                print(f"âœ… Whisperè¯­éŸ³è¯†åˆ«æˆåŠŸ: {transcript[:100]}...")
                return transcript
                
        except Exception as e:
            print(f"âŒ Whisper APIè°ƒç”¨å¤±è´¥: {str(e)}")
            # é™çº§åˆ°æ¨¡æ‹Ÿè¯†åˆ«
            return await self._mock_transcribe_audio(audio_file_path, source_language)
    
    async def _mock_transcribe_audio(self, audio_file_path: str, source_language: str) -> str:
        """æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ç»“æœ"""
        print("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ç»“æœ")
        
        # æ ¹æ®æºè¯­è¨€è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿç»“æœ
        mock_results = {
            "è‹±æ–‡": "This is a mock transcription result for English audio. The user is reporting an issue with the delivery service where the motorcycle delivery person couldn't find the address and had to cancel the service, leaving the user hungry.",
            "è¥¿ç­ç‰™è¯­": "Esta es una transcripciÃ³n simulada para audio en espaÃ±ol. El usuario estÃ¡ reportando un problema con el servicio de entrega donde el repartidor en motocicleta no pudo encontrar la direcciÃ³n y tuvo que cancelar el servicio, dejando al usuario con hambre.",
            "è‘¡è„ç‰™è¯­": "Esta Ã© uma transcriÃ§Ã£o simulada para Ã¡udio em portuguÃªs. O usuÃ¡rio estÃ¡ relatando um problema com o serviÃ§o de entrega onde o entregador de motocicleta nÃ£o conseguiu encontrar o endereÃ§o e teve que cancelar o serviÃ§o, deixando o usuÃ¡rio com fome.",
            "ä¸­æ–‡": "è¿™æ˜¯ä¸­æ–‡è¯­éŸ³è¯†åˆ«çš„æ¨¡æ‹Ÿç»“æœã€‚ç”¨æˆ·åé¦ˆé…é€æœåŠ¡å­˜åœ¨é—®é¢˜ï¼Œæ‘©æ‰˜è½¦é…é€å‘˜æ— æ³•æ‰¾åˆ°åœ°å€ï¼Œå¯¼è‡´æœåŠ¡å–æ¶ˆï¼Œç”¨æˆ·æ„Ÿåˆ°é¥¥é¥¿ã€‚"
        }
        
        return mock_results.get(source_language, "è¿™æ˜¯æ¨¡æ‹Ÿçš„è¯­éŸ³è¯†åˆ«ç»“æœï¼Œå®é™…åº”è¯¥è°ƒç”¨è¯­éŸ³è¯†åˆ«API")

    async def _parse_original_sound_response(self, content: str) -> Dict[str, Any]:
        """è§£æåŸå£°åˆ†æå“åº”"""
        try:
            # å°è¯•è§£æJSON
            if content.strip().startswith('{'):
                result = json.loads(content)
                return result
            else:
                # å¦‚æœä¸æ˜¯JSONï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    return result
                else:
                    print("âš ï¸ æ— æ³•è§£æåŸå£°åˆ†æå“åº”ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                    return await self._fallback_original_sound_analysis(
                        "ç”¨æˆ·åŸå£°", "ä¸­æ–‡", "ä¸­æ–‡"
                    )
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return await self._fallback_original_sound_analysis(
                "ç”¨æˆ·åŸå£°", "ä¸­æ–‡", "ä¸­æ–‡"
            )

    async def _fallback_original_sound_analysis(
        self,
        user_input: str,
        source_language: str,
        target_language: str
    ) -> Dict[str, Any]:
        """å¤‡ç”¨åŸå£°åˆ†ææ–¹æ³•"""
        print("ğŸ”„ ä½¿ç”¨å¤‡ç”¨åŸå£°åˆ†ææ–¹æ³•")
        
        # ç®€å•çš„æƒ…æ„Ÿåˆ†æ
        sentiment_classification = "ä¸­æ€§"
        sentiment_intensity = "ä¸­ç­‰"
        
        # åŸºäºå…³é”®è¯åˆ¤æ–­æƒ…æ„Ÿ
        negative_keywords = ["é—®é¢˜", "é”™è¯¯", "å¤±è´¥", "ä¸å¥½", "ç³Ÿç³•", "å¤±æœ›", "æ„¤æ€’", "ä¸æ»¡", "å–æ¶ˆ", "é¥¥é¥¿"]
        positive_keywords = ["å¥½", "ä¼˜ç§€", "æ»¡æ„", "æ„Ÿè°¢", "å–œæ¬¢", "æ¨è", "å®Œç¾"]
        
        if any(keyword in user_input.lower() for keyword in negative_keywords):
            sentiment_classification = "è´Ÿå‘"
            sentiment_intensity = "å¼ºçƒˆ" if any(word in user_input.lower() for word in ["æ„¤æ€’", "ç³Ÿç³•", "å¤±æœ›"]) else "ä¸­ç­‰"
        elif any(keyword in user_input.lower() for keyword in positive_keywords):
            sentiment_classification = "æ­£å‘"
            sentiment_intensity = "å¼ºçƒˆ" if any(word in user_input.lower() for word in ["å®Œç¾", "ä¼˜ç§€", "æ¨è"]) else "ä¸­ç­‰"
        
        # ç®€å•çš„ç¿»è¯‘ï¼ˆå®é™…åº”è¯¥è°ƒç”¨ç¿»è¯‘APIï¼‰
        original_translation = f"[{target_language}ç¿»è¯‘] {user_input}"
        
        # AIæ™ºèƒ½ä¼˜åŒ–æ€»ç»“
        ai_optimized_summary = f"ç”¨æˆ·åé¦ˆå…³äºé…é€æœåŠ¡çš„é—®é¢˜ï¼Œä¸»è¦æ¶‰åŠæ‘©æ‰˜è½¦é…é€å‘˜æ— æ³•æ‰¾åˆ°åœ°å€å¯¼è‡´æœåŠ¡å–æ¶ˆçš„é—®é¢˜ã€‚"
        
        # å…³é”®è¦ç‚¹
        key_points = f"â€¢ é…é€å‘˜æ— æ³•æ‰¾åˆ°åœ°å€\nâ€¢ æœåŠ¡è¢«å–æ¶ˆ\nâ€¢ ç”¨æˆ·æ„Ÿåˆ°é¥¥é¥¿\nâ€¢ å³ä½¿é€šè¿‡åº”ç”¨å‘é€äº†ä½ç½®ä¿¡æ¯"
        
        # æƒ…æ„Ÿåˆ†æè¯´æ˜
        sentiment_analysis = f"ç”¨æˆ·è¡¨è¾¾äº†å¯¹é…é€æœåŠ¡çš„ä¸æ»¡æƒ…ç»ªï¼Œä¸»è¦å› ä¸ºé…é€å‘˜æ— æ³•æ‰¾åˆ°åœ°å€å¯¼è‡´æœåŠ¡å–æ¶ˆï¼Œç»™ç”¨æˆ·å¸¦æ¥äº†ä¸ä¾¿ã€‚"
        
        return {
            "original_translation": original_translation,
            "ai_optimized_summary": ai_optimized_summary,
            "key_points": key_points,
            "sentiment_classification": sentiment_classification,
            "sentiment_intensity": sentiment_intensity,
            "sentiment_analysis": sentiment_analysis
        }
